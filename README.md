# PPO

Simple proximal policy optimisation + generalised advantage estimation + single/multi-discrete action space implementation. 

